\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english,italian]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{braket}
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{geometry}
\usepackage{float}          % Per controllare il posizionamento di tabelle e figure
\geometry{margin=1in}

% Metadata
\title{Fondamenti dell'Intelligenza Artificiale}
\author{Filippo Bianchi}
\date{\today}

\newcommand{\definizione}{\noindent\textbf{\underline{Def:}} }
\newcommand{\osservazione}{\noindent\textbf{\underline{Oss:}} }
\newcommand{\esempio}{\noindent\textbf{\underline{Es:}} }
\newcommand{\teorema}[1]{\noindent\textbf{\underline{Teorema #1 :}} }

\begin{document}

	\maketitle

	\tableofcontents

	\newpage

	\section{Richiami di Analisi}

	\subsection{Spazi Metrici}

	Dato un insieme $\textbf{X}$ andiamo a definire una \textit{metrica} (o \textit{distanza}) $d: X^2 \rightarrow \mathbb{R}$, tale che:

	\begin{enumerate}
		\item $\forall x,y \in \textbf{X} : d(x,y) \geq 0 \ \text{e} \ d(x,x) = 0$
		\item $\forall x,y \in \textbf{X} : d(x,y) = d(y,x)$
		\item $\forall x,y,z \in \textbf{X} : d(x,y) \leq d(x,z) + d(z,y) \ \textbf{(Disuguaglianza Triangolare)}$
	\end{enumerate}

	\noindent \textbf{\underline{ES:}} Distanza Euclidea

	\[
	\begin{array}{c}
		d : \mathbb{R}^2 \rightarrow \mathbb{R} \\
		(x, y) \mapsto |x - y|
	\end{array}
	\]

	\noindent \textbf{\underline{Def:}} Siano $x_0 \in \mathbb{R}, \ r \in \mathbb{R} \ \text{t.c. } r > 0$, allora si dice \textbf{Intorno Sferico} (o \textbf{Palla}) di \textit{centro} $x_0$ e \textit{raggio} $r$, l'insieme:

	\[
	B(x_0,r) = \{x \in \mathbb{R} : |x - x_0| < r\} = (x_0 - r, x_0 + r)
	\]

	\definizione Si definisce \textbf{Palla Chiusa} di \textit{centro} $x_0$ e di \textit{raggio} $r > 0$, l'insieme:

	\[
	\dot{B} (x_0,r) = \{ x \in \mathbb{R} : |x -x_0| \leq r \} = [x_0 - r, x_0 + r]
	\]

	\definizione Si consideri $ N \in \mathbb{N}, N > 0$ e si consideri il prodotto cartesiano $\mathbb{R}^N = \mathbb{R} \times \mathbb{R} \times ... \times \mathbb{R}$. Allora $\mathbb{R}^N$ è uno \textbf{Spazio Vettoriale}, con le seguenti proprietà:

	\begin{enumerate}
		\item (+) e ($\cdot$) sono \textit{associative} e \textit{commutative}
		\item $\exists 0 \in \mathbb{R}^N : x + 0 = x \ \forall x \in \mathbb{R}^N$
		\item $1 \cdot x = x \text{ e } 0 \cdot x = 0 \ \forall x \in \mathbb{R}^N$
		\item $ (\lambda + \mu) \cdot x = \lambda x + \mu x \text{ e } \lambda(x + y) = \lambda x + \lambda y$
		\item $\lambda (\mu \cdot x ) = (\lambda \cdot \mu) x$
	\end{enumerate}

	\definizione Si dice \textbf{Combinazione Lineare} di vettori $x,y \in \mathbb{R}^N$ e a coefficienti $\lambda, \mu \in \mathbb{R}$, il vettore:

	\[
	\lambda x + \mu y = (\lambda x_1 + \mu y_1, \lambda x_2 + \mu y_2, ..., \lambda x_N + \mu y_N) = (\lambda x_i + \mu y_i)_{i = 1}^N \in \mathbb{R}^N
	\]

	\definizione Si dice \textbf{Norma Euclidea} di $x \in \mathbb{R}^N$ la funzione $\| \cdot \| : \mathbb{R}^N \rightarrow \mathbb{R}$, t.c.

	\[
	\|x\| = \sqrt{\sum_{i=1}^{N} x_i^2}
	\]

	\definizione Si dice \textbf{Distanza Euclidea} tra $x$ e $y$ di $\mathbb{R}^N$, la distanza:

	\[
	\forall x,y \in \mathbb{R}^N \ \ \ d(x,y) = \|x - y \| = \sqrt{\sum_{i=1}^{N} (x_i - y_i)^2} \ \in \mathbb{R}
	\]

	\definizione Siano $x_0 \in \mathbb{R}^N$ e $r \in \mathbb{R}, r > 0$, si dice \textbf{Intorno Sferico} (o \textbf{Palla}) di $\mathbb{R}^N$ di \textit{centro} $x_0$ e \textit{raggio} $r$, l'insieme:

	\[
	B(x_0, r) = \{x \in \mathbb{R}^N : \| x - x_0 \| < r \}
	\]

	\definizione Si dice \textbf{Insieme Aperto} di $\mathbb{R}^N$ un insieme $A \subset \mathbb{R}^N, A \neq \emptyset$ t.c.

	\[
	\forall x \in A \ \exists r \in \mathbb{R}, r > 0 : B (x,r) \subseteq A
	\]

	\definizione Si definisce \textbf{Insieme Chiuso} di $\mathbb{R}^N$ il \textit{complementare} di un aperto. \\

	\noindent\textbf{\underline{Oss:} } Non esistono solo insieme aperti o chiusi, per esempio:

	\[
	A = [a,b) \subseteq \mathbb{R}, \text{ allora }  \overline{A} = (-\infty , a) \cup [b, \infty) \]
	Ma se considero $x \in A, x = a$ non riesco a trovare $r > 0$ t.c. $B(x,r) \subseteq A $ \\

	\definizione Si definisce \textbf{Prodotto Scalare} (o \textbf{Prodotto Interno}, o \textbf{Dot Product}) su $\mathbb{R}^N$, dati $x,y \in \mathbb{R}^N$:

	\[
	\langle x,y \rangle = x \cdot y = x_1 y_1 + x_2 y_2 + ... + x_N y_N = \sum_{i = 1}^{N} x_i y_i \ \in \mathbb{R}
	\]

	\definizione Si dice \textbf{Similarità del Coseno} la funzione su $\mathbb{R}^N$ data da:

	\[
	d(x,y) = \frac{x \cdot y}{\|x\| \cdot \| y\|} = cos(\theta), \text{ con } \theta \text{ angolo compreso tra } x,y.
	\]

	\definizione Si dice \textbf{Base Canonica} di $\mathbb{R}^N$ l'insieme di vettori $\mathcal{B} = \{ e_1, e_2, ..., e_N \}$ dati da:

	\[
	e_1 = (1, 0, ..., 0), \
	e_2 = (0, 1, 0, ..., 0), \
	... \ , \
	e_N = (0, ..., 0, 1),
	\]

	\noindent \textbf{\underline{Oss:} } I vettori della base canonica sono tra loro ortogonali e costituiscono dei proiettori per la rispettiva componente di vettori di dimensioni coerenti, siano $x \in \mathbb{R}^N, e_1 = (1, 0, ..., 0),$:

	\[\text{ posso ottenere la prima componente di } x \text{ nel seguente } x \cdot e_1 = x_1\]

	\subsection{Funzioni in più variabili}

	Con variabili si intende le \textit{componenti} di un vettore. Ci sono 3 modi per avere funzioni in più variabili:

	\begin{itemize}
		\item $ f : \mathbb{R}^N \rightarrow \mathbb{R} \ \ \ f(x) = f(x_1,x_2, ..., x_N) = y \in \mathbb{R}$
		\item $ f : \mathbb{R} \rightarrow \mathbb{R}^M \ \ \ f(x) = y = (y_1, y_2, ..., y_M) \in \mathbb{R}^M$
		\item $ f : \mathbb{R}^N \rightarrow \mathbb{R}^M \ \ \ f(x_1, x_2, ..., x_N) = (y_1, y_2, ..., y_M),$ \\ $ \forall (x_1, x_2, ..., x_N) \in \mathbb{R}^N \ \exists! \ (y_1, y_2, ..., y_M) \in \mathbb{R}^M : f(x_1, x_2, ..., x_N) = (y_1, y_2, ..., y_M)$
	\end{itemize}

	\noindent \textbf{Caso Generale}

	\noindent Sia $F : \mathbb{R}^N \rightarrow \mathbb{R}^M$ una \textit{funzione}, ovvero $\forall x \in \mathbb{R}^N \ \exists! \ y \in \mathbb{R}^M : F(x) = y$. Consideriamo le proiezioni di $y$ sulla base canonica di $\mathbb{R}^M$:

	\[
	x = \begin{bmatrix}
		x_1 \\ x_2 \\ ... \\ x_N
	\end{bmatrix} \mapsto
	\begin{bmatrix}
		y_1 \\ y_2 \\ ... \\ y_M
	\end{bmatrix}
	\]

	\noindent Siano $\pi_1, \pi_2, ... \pi_M$ i proiettori alle M componenti di $\mathbb{R}^M$, allora ho che

	\[
	f_1 = \pi_1 \circ F, f_2 = \pi_2 \circ F, ..., f_M = \pi_M \circ F
	\]

	danno come risultato la i-esima componente del vettore $y$, ossia del vettore risultante da $F(x)$. \\

	\definizione Si dice \textbf{Funzione Vettoriale}, una funzione del tipo:

	\[
	F = \begin{bmatrix}
		f_1 \\ f_2 \\ ... \\ f_M
	\end{bmatrix}
	\]
	con $f_i$ definiti come sopra. \\

	\definizione Una funzione $f : \mathbb{R}^N \rightarrow \mathbb{R}$ si dice \textbf{continua} e si indica $f \in \mathcal{C}^0(\mathbb{R}^N)$, se:

	\[
	\forall x \in \mathbb{R}^N, \forall \epsilon > 0, \exists \delta > 0 : \forall y \in \mathbb{R}^N, \| x - y\| < \delta \implies |f(x) - f(y) | < \epsilon
	\]

	\definizione Una funzione $f : \mathbb{R}^2 \rightarrow \mathbb{R}$ si dice \textbf{continua separatamente} in $x$ se \textit{fissato} $y$, la funzione $f_y = f(\cdot, y) : \mathbb{R} \rightarrow \mathbb{R}$ è \textbf{continua}.\\
	Analogamente si dice che è \textbf{continua separatamente} in $y$ se \textit{fissato} $x$, la funzione $f_x = f(x, \cdot) : \mathbb{R} \rightarrow \mathbb{R}$ è continua.

	\noindent \textbf{\underline{Oss:} } Ci sono funzioni continue separatamente in $x$ e in $y$ ma non continue su $\mathbb{R}^2$, per esempio:

	\[
	f : \mathbb{R}^2 \rightarrow \mathbb{R}, f(x,y) =
	\begin{large}
		\begin{cases}
			\frac{x \cdot y}{x^2 + y^2} & \text{ se } (x,y) \neq 0 \\
			0 & \text{ se } (x,y) = 0
		\end{cases}
	\end{large}
	\]

	\definizione Un vettore $v \in \mathbb{R}^N$ si dice \textbf{direzione} se $\| v \| = 1 $ \\

	\definizione Siano $x_0 \in \mathbb{R}^N$ e $ v \in \mathbb{R}^N, \| v \| = 1$, si dice \textbf{retta} passante per $x_0$ e direzione $v$, l'insieme:

	\[
	R(x_0,v) = \{ x \in \mathbb{R}^N : x = x_0 + t \cdot v, t \in \mathbb{R}\}
	\]

	\definizione Sia $f : \mathbb{R}^N \rightarrow \mathbb{R}$ una funzione, essa si dice \textbf{derivabile} in $x_0 \in \mathbb{R}^N$ e in \textit{direzione} $v \in \mathbb{R}^N$ se \textit{esiste finito} il limite del rapporto incrementale su $R(x_0,v)$:

	\[
	\lim_{t \rightarrow 0} \frac{f(x_0 + tv) - f(x_0)}{t} = \frac{\partial f}{\partial v} (x_0)
	\]

	\osservazione I vettori $e_i$ della base canonica di $\mathbb{R}^N$ sono \textit{direzioni}. \\

	\definizione Sia $f : \mathbb{R}^N \rightarrow \mathbb{R}$ una funzione, se esiste finito il limite del rapporto incrementale su $R(x_0, e_i)$ questo si dice \textbf{derivata parziale} di $f$ rispetto alla i-esima variabile $(x_i)$:

	\[
	\lim_{t \rightarrow 0} = \frac{f(x_0^{(0)}, x_1^{(0)}, ..., x_i^{(0)} + t, ..., x_N^{(0)}) - f(x_0)}{t} = \frac{\partial f}{\partial x_i} (x_0)
	\]

	\esempio Vedi appunti Iotti (01\_funzioni.pdf) \\

	\subsubsection{Funzioni Differenziabili}

	\definizione Siano $f : \mathbb{R}^N \rightarrow \mathbb{R}$ una funzione e $x_0 \in \mathbb{R}^N$, se \textit{esistono tutte} le derivate parziali in $x_0$, si definisce il \textbf{gradiente} di $f$ in $x_0$ il vettore:

	\[
	\nabla f(x_0) = ( \frac{\partial f}{\partial x_1} (x_0), \frac{\partial f}{\partial x_2} (x_0), ..., \frac{\partial f}{\partial x_N} (x_0) )
	\]

	\[
	\nabla f(x_0) \cdot v = \frac{\partial f}{\partial x_1} (x_0) \cdot v_1 + \frac{\partial f}{\partial x_2} (x_0) \cdot v_2 + ... + \frac{\partial f}{\partial x_N} (x_0) \cdot v_N = \sum_{i=1}^{N} v_i \cdot \frac{\partial f}{\partial x_i} (x_0)
	\]

	\definizione Sia $f : \mathbb{R}^N \rightarrow \mathbb{R}$ una funzione, si dice \textbf{differenziale} di $f$ in $x_0 \in \mathbb{R}^N$ data la direzione $v \in \mathbb{R}^N$, l'applicazione lineare:

	\[
	df_{x_0}(v) = \frac{\partial f}{\partial v} (x_0) = \sum_{i=1}^{N} v_i \cdot \frac{\partial f}{\partial x_i} (x_0)
	\]

	\noindent Notazione
	\[
	df_{x_0} = \sum_{i=1}^{N} v_i \cdot \frac{\partial f}{\partial x_i} (x_0) dx_i
	\]

	\definizione Una funzione $f : \mathbb{R}^N \rightarrow \mathbb{R}$ si dice \textbf{differenziabile} in $x_0$ quando esiste $df_{x_0}$ per ogni \textit{direzione} $v \in \mathbb{R}^N$. \\

	\noindent \textbf{Proprietà}: $f : \mathbb{R}^N \rightarrow \mathbb{R} \text{ differenziabile in } x_0 \implies$:

	\begin{enumerate}
		\item f \textbf{continua} in $x_0$
		\item \textbf{esiste} il piano tangente in $x_0$
		\item allora $\nabla f$ indica la \textbf{direzione di massima crescita}
	\end{enumerate}

	\osservazione Se $f : \mathbb{R}^N \rightarrow \mathbb{R}$ differenziabile, $df_{x_0}(v) = \nabla f (x_0) \cdot v$, quindi

	\[
	\nabla f(x_0) \perp v \iff df_{x_0}(v) = 0
	\]

	\esempio Vedi appunti Iotti (01\_funzioni.pdf) \\

	\teorema{} Sia $f : \mathbb{R}^N \rightarrow \mathbb{R}$ differenziabile. Se $x_0 \in \mathbb{R}^N$ è un \textbf{punto di massimo/minimo} per $f$, allora $df_{x_0} = 0$ in tutte le direzioni (ossia $\nabla f(x_0) = 0$). \\

	\teorema{} Sia $f : \mathbb{R}^N \rightarrow \mathbb{R}$ con derivate parziali in $B(x_0,r), r \in \mathbb{R}^N, r>0$ e tali derivate siano continue, allora f è \textbf{differenziabile}.

	\teorema{di Schwartz} Sia $f : A \subseteq \mathbb{R}^2 \rightarrow \mathbb{R}$ con $A$ aperto e $(x_0,y_0) \in A$, se le derivate seconde parziali \textit{miste} esistono in $B((x_0,y_0), r)$ e se \textit{sono continue}, allora:

	\[
	\frac{\partial^2 f}{\partial x \partial y} (x_0,y_0) = \frac{\partial^2 f}{\partial y \partial x} (x_0,y_0)
	\]

	\subparagraph{Metodo Iterativo per trovare punto di Minimo}

	\begin{enumerate}
		\item Scegliamo $x_0 \in \mathbb{R}$ nel \textbf{dominio} di $f$
		\item Ci spostiamo nel verso opposto rispetto a $f'$, lungo una \textbf{retta}
		\item Definiamo per ricorrenza la seguente successione:
		\[
		\begin{cases}
			x_0 = a \in \mathbb{R} \\
			x_n = x_{n-1} - \eta f'(x_{n_1})
		\end{cases}
		\]

		dove $n \in \mathbb{N}$ è il numero di iterazioni, mentre $\eta \in \mathbb{R}$ è detto \textbf{iperparametro}. In questo modo avremo una successione di questo tipo:

		\[
		x_1 = x_0 - \eta f'(x_0), \ x_2 = x_1 - \eta f'(x_1), ..., \ x_n = x_{n-1} - \eta f'(x_{n-1})
		\]
	\end{enumerate}

	\textit{Condizioni di terminazione} \\
	Vogliamo arrivare a $x_n$ punto di minimo:

	\begin{enumerate}
		\item $|f'(x_n)| < \epsilon $, se $f'(x_n) = 0 \implies x_{n+1} = x_n - \eta f'(x_n) = x_n$
		\item $|x_{n-1} - x_n| < \epsilon$
		\item $n > T$ (iterazioni)
	\end{enumerate}

	\subsubsection{Algoritmo di discesa del Gradiente}

	\noindent L'algoritmo di discesa del gradiente è analogo al metodo iterativo mostrato sopra, adattato alle funzioni in più variabili:

	\[
	\begin{cases}
		x_0 = a \in \mathbb{R} \\
		x_n = x_{n-1} - \eta \nabla f(x_{n_1})
	\end{cases}
	\]

	dove $\eta$ è l'iperparametro, anche detto \textbf{learning rate}. In modo analogo si possono adattare le strategie di terminazione:

	\begin{enumerate}
		\item $ \| \nabla f(x_n)\| < \epsilon $
		\item $ \| x_n - x_{n-1}\| < \epsilon $
		\item $n > T$ ($T$ soglia)
	\end{enumerate}

	\subsubsection{Derivata della Funzione Composta}

	$N = 1, f : \mathbb{R} \rightarrow \mathbb{R}, g : \mathbb{R} \rightarrow \mathbb{R}, f \circ g : \mathbb{R} \rightarrow \mathbb{R} \rightarrow \mathbb{R} \ \ x \mapsto g(x) \mapsto f(g(x))$

	\[
	\frac{d f(g(x_0))}{d x} = \frac{d f(g(x_0))}{d g} \cdot \frac{d g}{d x}(x_0)
	\]

	\noindent $N > 1$ ci sono 3 casi:

	\begin{enumerate}
		\item $ f : \mathbb{R}^N \rightarrow \mathbb{R}, g : \mathbb{R} \rightarrow \mathbb{R}^N, f \circ g : \mathbb{R} \rightarrow \mathbb{R}^N \rightarrow \mathbb{R} \ \ x \mapsto g(x) \mapsto f(g(x))$
		\item $ f : \mathbb{R}^N \rightarrow \mathbb{R}, g : \mathbb{R}^M \rightarrow \mathbb{R}^N, f \circ g : \mathbb{R}^M \rightarrow \mathbb{R}^N \rightarrow \mathbb{R}$
		\item $ f : \mathbb{R}N \rightarrow \mathbb{R}^K, g : \mathbb{R}^M \rightarrow \mathbb{R}^N, f \circ g : \mathbb{R}^M \rightarrow \mathbb{R}^N \rightarrow \mathbb{R}^K$
	\end{enumerate}

	Derivata di 1.

	\[
	\frac{df(g(x_0))}{dx} = \sum_{i = 1}^{N} \frac{\partial f}{\partial g_i} (g(x_0)) \cdot \frac{dg_i}{dx} (x_0), \text{ con } g_i : \mathbb{R} \rightarrow \mathbb{R}
	\]

	Derivata di 2. $ x_0 \in \mathbb{R}^M, i = 1, ..., M, \ g: \mathbb{R}^M \rightarrow \mathbb{R}^N$

	\[
	\frac{\partial f(g(x_0))}{\partial x_i} = \sum_{k = 1}^{N} \frac{\partial f}{\partial g_k} (g(x_0)) \cdot \frac{\partial g_k}{\partial x_i} (x_0), \text{ con } g_k : \mathbb{R}^M \rightarrow \mathbb{R}
	\]

	\[
	\nabla f(g(x_0)) = \frac{\partial f (g(x_0))}{\partial x_1}, ..., \frac{\partial f(g(x_0))}{\partial x_M})
	\]

	\subsection{Polinomi di Taylor}
	\label{subsec:taylor}

	\teorema{Sviluppo in Serie di Taylor} \\

	\noindent Se $f : \mathbb{R} \rightarrow \mathbb{R}$ di ordine $\mathcal{C}^k(\mathbb{R})$, sia $x_0 \in \mathbb{R}$ e $x \in \mathcal{B}(x_0, r),\  r \in \mathbb{R},\ r > 0$. Allora:

	\[
	f(x) = \sum_{ i = 0}^{k} \frac{f^{(1)} (x_0)}{i!} \cdot (x - x_0)^i + R_k(x) \cdot(x - x_0) ^k
	\]

	dove $\sum_{ i = 0}^{k} \frac{f^{(1)} (x_0)}{i!} $ è il polinomio di Taylor, mentre $R_k(x) \cdot(x - x_0) ^k$ è il resto. Si ha che $\lim_{x \rightarrow x_0} R_k(x) = 0$.

	\esempio $N = 2$

	\[
	f : \mathbb{R}^2 \rightarrow \mathbb{R}, \ f(x,y) = x^2 + y \cdot e^x, \text{ indici (prima,seconda) variabili} (i,j)
	\]

	\[
	\frac{\partial^1 f}{\partial x^1} = 2x + y \cdot e^x \ (1,0), \ \ \ \frac{\partial^1 f}{\partial y^1} = e^x (0,1)
	\]
	\[
	\frac{\partial^2 f}{\partial x^2} = 2 + y \cdot e^x \ (2,0), \ \ \
	\frac{\partial^2 f}{\partial y^2} = 0 \ (0,2) \ \ \
	\]
	\[
	\frac{\partial^{1+1} f}{\partial x^1 \partial y^1} = e^x \ (1,1), \text{ con } i = 0,1,2,\ j=0,1,2 \text{ multi-indici}
	\]

	\definizione Sia $f : \mathbb{R}^N \rightarrow R$, definisco:

	\[
	\partial^\alpha f = \frac{\partial^{\alpha_1 + \alpha_2 + ... + \alpha_N} f}{\partial x_1^{\alpha_1} \cdot \partial x_2^{\alpha_2} \cdot ... \cdot \partial x_N^{\alpha_N}}
	\]

	con $\alpha$ multi-indice, ossia $\alpha = (\alpha_1, \alpha_2, ..., \alpha_N)$ e $|\alpha| = \alpha_1 + \alpha_2 + ... + \alpha_N$. \\ \\
 	\teorema{ di Taylor}
 	Se $f : \mathbb{R}^N \rightarrow \mathbb{R}, f \in \mathcal{C}^k(A)$ con $A \subseteq \mathbb{R}^N$ aperto, dato $x_0 \in A$, per $ x \in \mathcal{B}(x_0,r), r > 0, r \in \mathbb{R}$, si ha:

 	\[
 	f(x) = \sum_{|\alpha| \leq k} \frac{\partial ^\alpha f(x_0)}{\alpha !} \cdot (x - x_0)^\alpha + \sum_{|\alpha| \leq k} R_\alpha (x) \cdot (x - x_0)^\alpha
 	\]

 	dove $ \sum_{|\alpha| \leq k} \frac{\partial ^\alpha f(x_0)}{\alpha !} \cdot (x - x_0)^\alpha$ è il \textbf{polinomio di Taylor}, e $\sum_{|\alpha| \leq k} R_\alpha (x) \cdot (x - x_0)^\alpha$ è il resto, per cui vale il seguente

 	\[
 	\lim_{x \rightarrow x_0} R_\alpha(x) = 0
 	\]

 	\esempio $f(x,y) = x^2 + y\cdot e^x, k = 2, \ x_0 = (0,0), \ \alpha = (\alpha_1, \alpha_2) = \{(0,0), (0,1), (1,0),(1,1), (2,0), (0,2) \}$

 	\begin{align*}
 		f(x, y) \cong \ & f(0,0)
 		+ \frac{\partial f}{\partial x}(0,0) \cdot x
 		+ \frac{\partial f}{\partial y}(0,0) \cdot y \\
 		& + \frac{\partial^2 f}{\partial x \partial y}(0,0) \cdot 2xy \cdot \frac{1}{1! \cdot 1!} \\
 		& + \frac{\partial^2 f}{\partial x^2}(0,0) \cdot x^2 \cdot \frac{1}{2! \cdot 0!} \\
 		& + \frac{\partial^2 f}{\partial y^2}(0,0) \cdot y^2 \cdot \frac{1}{0! \cdot 2!}
 	\end{align*}

 	ma si ha che $f(0,0) = 0,\ \frac{\partial f}{\partial x}(0,0) = 0,\ \frac{\partial f}{\partial y}(0,0) = 1, \ \frac{\partial^2 f}{\partial x \partial y} (0,0) = 1, \ \frac{\partial^2 f}{\partial y^2}(0,0) = 0,$ $ \ \frac{\partial^2 f}{\partial x^2}(0,0) = 2$. Allora si ha che:

 	\[
 	f(x,y) \stackrel{\sim}{=} y + 2xy + x^2
 	\]


	\section{Intelligenza Artificiale}

	L'intelligenza artificiale può essere classificata secondo due parametri:

	\begin{itemize}
		\item Pensare
		\begin{itemize}
			\item Come un essere umano --> Reti neurali (Percezione)
			\item Razionalmente --> Sistema esperto (Logica)
		\end{itemize}
		\item Agire
		\begin{itemize}
			\item Come un essere umano --> Imitazione
			\item Razionalmente --> Agenti (Strategia Ottimale)
		\end{itemize}
	\end{itemize}

	\noindent L'intelligenza artificiale (AI) si può suddividere in:

	\begin{itemize}
		\item Debole
		\begin{itemize}
			\item Non arriva all'intelligenza umana
			\item Supporto/Assistenza
		\end{itemize}
		\item Forte
		\begin{itemize}
			\item Può arrivare ad eguagliare l'intelligenza umana
			\item AGI (Artificial General Intelligence)
		\end{itemize}
	\end{itemize}

	\subsection{Reti Neurali}

	Il modello base è quello del \textbf{Percettrone} (o Neurone), che prende in input un vettore $x \in \mathbb{R}^N, N \in \mathbb{N}$ di valori e produce 1 singolo valore in output:

	\[
	f(x) = \begin{cases}
		0 & \text{ se } \sum_{i=1}^{N} x_i \cdot w_i \leq T \\
		1 & \text{ se } \sum_{i=1}^{N} x_i \cdot w_i  > T
	\end{cases}
	\]

	Ciò che determina l'output è $(w \cdot x + b)$, con $b = -T$. Quest'ultima si usa per approssimare $f^* : \mathbb{R}^N  \rightarrow \{0,1\}$:

	\[
	f(x) = \begin{cases}
		0 & \text{ se } w \cdot x + b \leq 0 \\
		1 & \text{ se } w \cdot x + b > 0
	\end{cases}, \text{ con } w \in \mathbb{R}^N \text{ pesi }, b \in \mathbb{R} \text{ bias}
	\]

	\definizione Si dicono \textbf{parametri} di un \textbf{percettrone} i \textit{pesi} $ (w_i)_{i=1}^N \in \mathbb{R}^N$ sugli archi entranti e il \textit{bias} $b \in \mathbb{R}$ associato al nodo. \\

	\noindent Il problema è quindi scegliere $w$ e $b$ in modo appropriato per approssimare $f^*$ \\

	\definizione Si dice \textbf{Neurone Artificiale} un \textit{percettrone} a cui sia applicata una \textbf{funzione di attivazione}: $ \sigma : \mathbb{R} \rightarrow \mathbb{R}$ \textbf{NON} decrescente.

	\esempio Funzione di Heaviside

	\[
	\sigma \mathbb{R} \rightarrow \mathbb{R} \ \ \ \sigma(x) = \begin{cases}
		0 & \text{ se } x \leq 0 \\
		1 & \text{ se } x > 0
	\end{cases}
	\]

	Quindi $f$ diventa:

	\[
	f(x) = \sigma(w \cdot x + b) = \begin{cases}
		0 & \text{ se } \ w \cdot x + b \leq 0 \\
		1 & \text{ se } \ w \cdot x + b > 0
	\end{cases}
	\]

	\definizione Si dice \textbf{Single Layer Perceptron} un \textit{grafo} $G = (V, E)$ \textit{diretto, bipartito e aciclico} i cui vettori sono neuroni artificiali

	\[
	A,B \subseteq V, \textbf{ t.c. } A \cap B = \emptyset \land A \cup B = V, \ \ A \text{ e } B \text{ si dicono } \textbf{strati}
 	\]

	\[
	f_\theta : \mathbb{R}^N \rightarrow \mathbb{R}^M \text{ è l'SLP, dove } \theta = (W, b) \text{ sono i parametri}
	\]

	In particolare i parametri sono:
	\begin{itemize}
		\item \textbf{Vettore di Bias} $ b = (b_i)_{i = 1}^M \in \mathbb{R}^M$
		\item \textbf{Matrice dei Pesi} $ W = (w_{ij})_{i=1, j=1}^{N,M} \in \mathbb{R}^{N \times M}$
	\end{itemize}

	La funzione obiettivo è

	\[
	f^* : \mathbb{R}^N \rightarrow {0,1}^M, \text{ oppure } f^* : \mathbb{R}^N \rightarrow \mathbb{R}^M
	\]

	Quindi ho

	\[
	f_\theta(x) =( \sigma (\sum_{i=1}^{N} w_{ij} \cdot x_i + b_j))_{j=1}^M
	\]

	La struttura è la seguente:
	\begin{itemize}
		\item Un primo strato, detto strato di \textbf{input}, composto da $N$ nodi (ossia un vettore di $\mathbb{R}^N$). Ognuno di questi nodi presenta un arco entrante allo strato successivo.
		\item Oltre allo strato di input è presente un solo altro strato, detto di \textbf{output}, composto da $M$ nodi. Ogni nodo di questo strato riceve in input il valore di tutti i nodi dello strato precedente, a cui applica i pesi della matrice dei pesi e il bias, secondo la formula $w_ij \cdot x_i + b_j$, con $i = 1,...,N, \text{ e } j = 1,...,M $. Infine viene applicata la \textbf{funzione di attivazione}, dalla quale si ottiene il vettore $y \in \mathbb{R}^M$ ossia l'output dell'SLP.
	\end{itemize}

	\osservazione Se la funzione di attivazione $\sigma$ è la funzione di Heaviside il problema è mal condizionato: questo perchè 0 è un punto critico di questa funzione, in quanto essendo presente una discontinuità, piccole variazioni ai parametri cambiano completamente l'output.

	\subsection{Funzioni di Attivazione}

	Le funzioni di attivazione sono $\sigma : \mathbb{R} \rightarrow \mathbb{R}$ non decrescenti, ma \textit{desideriamo} scegliere tra alcune proprietà utili:

	\begin{enumerate}
		\item $\sigma $ sia \textbf{continua}, $\sigma \in \mathcal{C}^0(\mathbb{R})$
		\item $\sigma $ sia \textbf{continua, derivabile} con derivata \textbf{continua}, $\sigma \in \mathcal{C}^1(\mathbb{R})$
		\item $\sigma$ sia \textbf{limitata}
		\[
		\exists L \in \mathbb{R}, L \geq 0 : \forall x \in \mathbb{R}, \| \sigma(x) \| \leq L
		\]
	\end{enumerate}

	In seguito vengono mostrate alcune funzioni di attivazione:

	\begin{enumerate}
		\item \textbf{Sigmoide Logistica (RELU)} $ \sigma : \mathbb{R} \rightarrow \mathbb{R}, \sigma \in \mathcal{C}^\infty(\mathbb{R})$

		\[
		\sigma_\beta(x) = \frac{1}{1 + e^{- \beta x}} \\
		\frac{\partial \sigma}{\partial x}(x) = \frac{\beta e^{- \beta x}}{(1 -+ e^{- \beta x})^2} = \beta \cdot  \frac{1}{1 + e^{- \beta x}} \cdot  \frac{ e^{- \beta x}}{1 + e^{- \beta x}}
		\]

		ma l'ultimo fattore lo posso riscrivere come
		\[
		1 -  \frac{1}{1 + e^{- \beta x}} =  \frac{ 1 + e^{- \beta x} - 1}{1 + e^{- \beta x}} =  \frac{e^{- \beta x}}{1 + e^{- \beta x}}
		\]

		quindi ho che

		\[
		\beta \cdot  \frac{1}{1 + e^{- \beta x}} \cdot  \frac{ e^{- \beta x}}{1 + e^{- \beta x}} = \beta \cdot  \frac{1}{1 + e^{- \beta x}} \cdot (1 -  \frac{1}{1 + e^{- \beta x}}) = \beta \cdot \sigma_\beta(x) \cdot (1 - \sigma_\beta(x))
		\]

		Considero il seguente limite

		\[
		\lim_{\beta \rightarrow \infty} \sigma_\beta(x) = \lim_{\beta \rightarrow \infty} \frac{1}{1 + e^{- \beta x}} = \begin{cases}
			0 & \text{ se } x < 0 \\
			1 & \text{ se } x \geq
		\end{cases}
		\]

		\osservazione Il problema non è più mal condizionato, in quanto non sono presenti punti critici nella funzione.

		\item \textbf{Rectified Linear Unit (RELU)} $\sigma : \mathbb{R} \rightarrow \mathbb{R}, \sigma \in \mathcal{C}^0(\mathbb{R})$

		\[
		\sigma (x) = \max \{0,x\} = \begin{cases}
			0 & \text{ se } x \leq 0 \\
			x & \text{ se } x > 0
		\end{cases}
		\]

		La cui derivata è

		\[
		\frac{\partial \sigma}{\partial x} (x) = \begin{cases}
			0 & \text{ se } x \leq 0 \\
			1 & \text{ se } x > 0
		\end{cases}
		\]

		\item \textbf{Soft Plus - Smooth RELU} $\sigma : \mathbb{R} \rightarrow \mathbb{R}, \sigma \in \mathcal{C}^\infty(\mathbb{R})$

		\[
		\beta \in \mathbb{R}, \beta > 0 \sigma_\beta(x) = \frac{1}{\beta} \log(1 + e^{\beta x})
		\]

		La cui derivata è

		\[
		\frac{\partial \sigma_\beta}{\partial x} (x) = \frac{1}{\beta} \cdot \frac{1}{1 + e^{\beta x}} \cdot \beta \cdot e^{\beta x}
		\]

		Considero il seguente limite

		\[
		\lim_{\beta \rightarrow \infty} \sigma_\beta(x) = \lim_{\beta \rightarrow \infty}  \frac{1}{\beta} \cdot \log(1 + e^{\beta x}) = \begin{cases}
			0 & \text{ se } x \leq 0 \\
			x & \text{ se } x > 0
		\end{cases}
		\]

		Nel limite mostrato sopra si ha che è uguale a $x$ se $x > 0$ perché, derivando rispetto a $\beta$ si ha:

		\[
		\lim_{\beta \rightarrow \infty}  \frac{1}{\beta} \cdot \log(1 + e^{\beta x}) = \lim_{\beta \rightarrow \infty} \frac{x \cdot e^{\beta x}}{ 1 + e^{\beta x}} = \lim_{\beta \rightarrow \infty} x \cdot \frac{e^{\beta x}}{e^{\beta x} \cdot (\frac{1}{e^{\beta x}} + 1)} = x
		\]

		Questo perché, nell'ultima equazione si ha che $e^{\beta x}$ a numeratore e denominatore si semplificano, mentre $\frac{1}{e^{\beta} x}$ tende a 0 per $\beta \rightarrow \infty$.

		\item \textbf{Tangente Iperbolica (TANH)} $\sigma : \mathbb{R} \rightarrow \mathbb{R}, \sigma \in \mathcal{C}^\infty(\mathbb{R})$

		\[
		\beta \in \mathbb{R}, \beta > 0, \sigma_\beta(x) = \tanh(\beta x) = \frac{e^{\beta x} - e^{- \beta x}}{e^{\beta x} + e^{- \beta x}} = \frac{e^{2\beta x} - 1}{e^{2\beta x} + 1} = \frac{1 - e^{-2 \beta x}}{1 + e^{-2 \beta x}}
		\]

		La cui derivata è

		\[
		\frac{\partial \sigma_\beta}{\partial x}(x) = \beta \cdot (1 - \tanh^2(\beta x))
		\]

		Considero il seguente limite

		\[
		\lim_{\beta \rightarrow \infty} \sigma_\beta (x) = \lim_{\beta \rightarrow \infty} \frac{e^{\beta x} - e^{- \beta x}}{e^{\beta x} + e^{- \beta x}} = \begin{cases}
			\frac{e^{\beta x}}{e^{\beta x}} = 1 & \text{ se } x > 0 \\
			0 & \text{ se } x = 0 \\
			-\frac{e^{- \beta x}}{e^{- \beta x}} = 1 & \text{ se } x < 0
		\end{cases}
		\]
	\end{enumerate}

	\definizione Si dice \textbf{Multi-Layer Perceptron (MLP)} un grafo $G = (V,E)$, \textit{diretto} e \textit{aciclico} con $L$ \textit{strati} + 1 \textit{strato di input}

	\[
	A_0, A_1, ..., A_L \subseteq V \text{ t.c. } \textit{disgiunti} \text{ a due a due, ossia } A_0 \cup A_1 \cup ... A_L = V
	\]

	Per ogni strato, a differenza di quello di input, tutti i nodi dello strato ricevono in ingresso i valori di ogni nodo dello strato precedente, a cui applicano il proprio peso, bias e la funzione di attivazione, producendo un singolo valore di output, che passano a tutti i nodi dello strato successivo. \'E possibile descrivere questo con la seguente funzione

	\[
	F \rightarrow \mathbb{R}^N \rightarrow \mathbb{R}^{n_1} \rightarrow ... \rightarrow \mathbb{R}^{n_{L - 1}} \rightarrow \mathbb{R}^L
	\]

	\osservazione Ogni coppia si stati consecutivi costituisce un SLP. \\

	\definizione Definizione ricorsiva di $F$:

	\[
	\begin{cases}
		F_0 (x) = x \\
		F_k (x) = \sigma ( W^{(k)T} \cdot F_{k -1}(x) + b^{(k)})
	\end{cases}
	\]

	Caso $L = 1$:

	\[
	F(x) = \sigma ( W^{(2) T} \cdot \sigma(W^{(1) T} \cdot x +b^{(1)} ) + b^{(2)} )
	\]

	\osservazione Nel caso appena mostrato è immediato vedere che l'equazione interna $ \sigma(W^{(1) T} \cdot x +b^{(1)}) $ rappresenta un SLP. \\

	\subsection{Discesa del gradiente su SLP e MLP}

	Problema: trovare i parametri $\theta = (W, b)$ t.c. il \textbf{modello} $ f_\theta : \mathbb{R}^N \rightarrow \mathbb{R}^M$ \textbf{ approssimi bene } $ f^* : \mathbb{R}^N \rightarrow \mathbb{R}^M$. Una strategia è l'\textbf{apprendimento supervisionato}, ovvero tramite esempi. \\

	\textbf{\underline{Dataset:}}\\

	$
	D = \{ (x,y) = (x, f(x)), x \in \mathbb{R}^N, y \in \mathbb{R}^M \} = D_{\text{train}} \cup D_{\text{val}} \cup D_{\text{test}} \text{ (disgiunti a due a due)}
	$ \\

	Con \textit{interpolazione} (metodi numerici) e \textit{fitting} (come regressione). \\

	\textbf{\underline{Ottimizzazioni sul Dataset:}}

	\begin{enumerate}
		\item Stabilire un \textbf{costo} $ \| f_\theta (x) - f^*(x)\|$ (esempio)
		\item Minimizzare il costo $\min_{\theta \sim (W,b)}  \| f_\theta (x) - f^*(x)\| $
	\end{enumerate}


	\definizione Si dice \textbf{Funzione di Costo} (o \textit{perdita}, o \textit{loss}) una funzione $ \mathcal{L}$ definita su un \textit{dataset} $D$, ovvero $\mathcal{L} \rightarrow \mathbb{R}$. \\

	\esempio Loss $\mathcal{L}_1$

	\[
	\mathcal{L}_1 (D) = \sum_{i = 1}^{n} \| f_\theta (x^{(i)}) - f^* (x^{(i)}) \| = \sum_{i = 1}^{n} \| f_\theta (x^{(i)}) - y^{(i)} \|, \text{ con } |D| = n
	\]

	\subsubsection{Funzioni di Costo}

	\begin{enumerate}
		\item Loss $\mathcal{L}_1 \ \ \ |D| = 2, f^* : \mathbb{R} \rightarrow \mathbb{R}, \text{ SLP o MLP } f_\theta : \mathbb{R} \rightarrow \mathbb{R} $

		\[
		\mathcal{L}_1 (D) = | f_\theta(x_1) - f^*(x_1)| + | f_\theta(x_2) - f^*(x_2) |
		\]
		\item Loss $\mathcal{L}_2$, \textbf{Errore Quadratico Medio} (Mean Squared Error (MSE)), $|D| = n, \\  f_\theta, f^* : \mathbb{R} \rightarrow \mathbb{R}$

		\[
		\mathcal{L}_2 (D) = \frac{1}{2n} \sum_{i = 1}^{n} \| f_\theta (x^{(i)}) - f^*(x^{(i)})  \|^2, \text{ con } f^*(x^{(i)}) = y^{(i)}
		\]

		\esempio Loss $\mathcal{L}_2$ su SLP, $f_\theta : \mathbb{R} \rightarrow \mathbb{R}, |D| = n, \theta = (W,b)$
		\[
		\mathcal{L}_2^{\text{SLP}} = \frac{1}{2n} \sum_{i = 1}^{n} \| \sigma (W^T \cdot x^{(i)} + b ) - f^*(x^{(i)}) \|^2 = \mathcal{L}_2^{\text{SLP}}(W,b), \text{ con }  f^*(x^{(i)}) = y^{(i)}
		\]

		\esempio Loss $\mathcal{L}_2$ su MLP, $ f_\theta : \mathbb{R} \rightarrow \mathbb{R}, L = 1, |D| = n, \theta = (W^{(1)}, W^{(2)}, b^{(1)}, b^{(2)})$

		\begin{align*}
			\mathcal{L}_2^{\text{MLP}} (D) &= \frac{1}{2n} \sum_{i=1}^{n} \| \sigma ( W^{(2)T} \cdot \sigma(W^{(1) T} \cdot x^{(i)} + b^{(1)} ) + b^{(2)} ) - y^{(i)}\|^2 \\
			&= \mathcal{L}_2^{\text{MLP}}(W^{(1)}, W^{(2)}, b^{(1)}, b^{(2)}) \\
			&= \mathcal{L}_2^{\text{MLP}}(\theta)
		\end{align*}

	\end{enumerate}

	\subsubsection{Discesa del gradiente su SLP}

	\[
	\mathcal{L}_2 (W,b) = \frac{1}{2n} \sum_{k = 1}^{n} \| \sigma (W^T \cdot x^{(k)} + b) - y^{(k)} \|^2
	\]

	\noindent Nella precedente formula si possono evidenziare le seguenti componenti:

	\begin{enumerate}
		\item \textbf{Pre-attivazione}
		\[
		s(W,b) = W^T \cdot x^{(k)} + b
		\]
		\item \textbf{Attivazione}
		\[
		\sigma ( s(W,b))
		\]
		\item \textbf{Norma/Distanza}
		\[
		\| \sigma - y^{(k)} \|
		\]
		\item
		\[
		x \mapsto x^2 : \| \sigma - y^{(k)} \|^2
		\]
	\end{enumerate}

	\noindent \'E necessario calcolare
	\[
	 \nabla_\theta \mathcal{L}_2 \rightarrow \frac{\partial \mathcal{L}_2}{\partial w_{i,j}} \text{ e } \frac{\partial \mathcal{L}_2}{ \partial b_i}
	\]

	\noindent Riprendendo le componenti evidenziate sopra si ha:

	\begin{enumerate}
		\item $ s(W,b) = W^T \cdot x + b, \ \ s: \mathbb{R}^{N \times M + M} \rightarrow \mathbb{R}^M$

		\[
		s_k(W,b) = w_{1k} \cdot x_1 + w_{2k} \cdot x_2 + ... + w_{Nk} \cdot x_N + b_k
		\]

		Considerando $i$ input e $j$ neurone, si ha che

		\[
		\begin{cases}
			\frac{\partial s_k}{\partial w_{ij}} = 0 & \text{ se } k \neq j \\
			\frac{\partial s_k}{\partial w_{ij}} = x_i & \text{ se } k = j
		\end{cases}
		\]

		\item $\sigma :  \mathbb{R} \rightarrow \mathbb{R}, \ \ \sigma \circ s : \mathbb{R}^{N \times M + M} \rightarrow \mathbb{R}$

		\[
		\sigma(s_j(W,b))
		\]

		Considerando $i$ input e $j$ neurone, si ha che

		\[
		\begin{cases}
			\frac{d \sigma(s_k)}{d w_{ij}} = 0 & \text{ se } k \neq j \\
			\frac{d \sigma(s_k)}{d w_{ij}} = \frac{d \sigma(s_k)}{d w_{ij}} \cdot \frac{\partial s_k }{\partial w_{ij}} \overset{\text{(1)}}{=} \sigma ' (s_k) \cdot x_i & \text{ se } k = j
		\end{cases}
		\]

		\item $f : \mathbb{R}^M \rightarrow \mathbb{R} \ \ f(x) \mapsto \| x\|, \ \ f( \sigma (s) - y) : \mathbb{R}^{N \times M + M} \rightarrow \mathbb{R}^M \rightarrow \mathbb{R} $

		\[
		\frac{\partial f}{\partial x_i} (x) = \frac{x_i}{ \| x \|}
		\]

		Considerando $i$ input e $j$ neurone, si ha che

		\[
		\frac{\partial f}{\partial w_{ij}}( \sigma(s) - y) = \sum_{k = 1}^{M} \frac{\partial f (\sigma(s) - y)}{\partial \sigma(s_k)} \cdot \frac{\sigma (s_k)}{\partial w_{ij}} \overset{\text{(1) + (2)}}{ = } \frac{\partial f (\sigma(s) - y )}{\partial \sigma(s_j)} \cdot \sigma'(s_j) \cdot x_i = \frac{ \sigma(s_j) - y_j}{\| \sigma(s) - y \|} \cdot \sigma'(s_j) \cdot x_i
		\]


		\item

		\[
		\frac{\partial \mathcal{L}_2}{ \partial w_{ij}} = \frac{1}{2n} \sum_{k = 1}^{n} 2 \cdot \| \sigma(s) - y\| \cdot \frac{ \sigma(s_j) - y_j}{\| \sigma(s) - y \|} \cdot \sigma' (s_j) \cdot x_i = \frac{1}{n} \sum_{k = 1}^{n} (\sigma(s) - y_j^{(k)}) \cdot \sigma'(s_j) \cdot x_i^{(k)}
		\]

		La seguente parte rappresenta l'errore sul neurone di output $j$

		\[
		(\sigma(s) - y_j^{(k)}) \cdot \sigma'(s_j)
		\]
	\end{enumerate}

	\subsubsection{Discesa del gradiente su MLP}

	Vedi appunti Iotti (02\_intelligenza artificiale).
	\[
	\frac{\partial \mathcal{L}_2}{\partial w_{ij}^{(2)}} = \text{ (SLP) } = \frac{1}{n} \sum_{k=1}^{n} ( \sigma(s_j^{(2)}) - y_j^{(k)} )\cdot \sigma'(s_j^{(2)})  \cdot \sigma(s_j^{(1)})
	\]
	\[
	\frac{\partial \mathcal{L}_2}{\partial w_{ij}^{(1)}} = \frac{1}{n} \sum_{k = 1}^{n} \left( \sum_{v = 1}^{M} ( \sigma(s_v) - y_v^{(k)}) \cdot \sigma'(s_v) \cdot w_{jv}^{(2)} \right) \cdot \sigma'(s_j) \cdot x_i^{(k)}
	\]

	\subsection{Algoritmo di Backpropagation}

	\definizione Si dice \textbf{Errore nello strato di output} il vettore $\delta ^{(L + 1)} \in \mathbb{R}^M$, tale che:

	\[
	\delta_v^{(L + 1)} = ( \sigma (s_v^{(L + 1)}) - y_v) \cdot \sigma' (s_v^{(L + 1)}), \text{ con } \sigma(s_v^{(L+1)}) \text{ output della rete.}
	\]
	In forma vettoriale:

	\[
	\delta^{(L + 1)} = ( \sigma (s^{(L + 1)}) - y) \cdot \sigma' (s^{(L + 1)})
	\]

	\definizione Si dice \textbf{Errore sugli strati nascosti} il vettore $\delta^{(l)} \in \mathbb{R}^{n_l}$, tale che:

	\[
	\delta_j^{(l)} = \sum_{v = 1}^{n_l} \delta_v^{(l+1)} \cdot w_{jv}^{(l + 1)} \cdot \sigma'(s_j^{(l)})
	\]

	\noindent \textbf{Equazioni della Backpropagation}

	\[
	\frac{\partial \mathcal{L}}{\partial w_{ij}^{(l)}} = \frac{1}{n} \sum_{k = 1}^{n} \delta_j^{(k)} \cdot \sigma ( s_j^{(l - 1)}),
	\]

	dove $\sigma ( s_j^{(l - 1)})$ è l'attivazione del layer \textit{l - 1}, input del layer corrente \textit{l}.

	\esempio

	\[
	\frac{\partial \mathcal{L}}{\partial w_{ij}^{(1)}} = \frac{1}{n} \sum_{k=1}^{n} \delta_j^{(1)} \cdot x_i^{(k)}
	\]

	\subsection{Algoritmo di Addestramento (di MLP)}

	\'E necessario definire:

	\begin{enumerate}
		\item \textbf{Iperparametri}: $ \eta \in \mathbb{R}, \eta > 0$, \textit{Learning Rate} (coefficiente di apprendimento), $N_{epoche}$, epoche di addestramento.
		\item \textbf{Input}: $D_{train} = \{ (x^{(1)}, y^{(1)}), ..., (x^{(n)}, y^{(n)}) \}, x^{(i)} \in \mathbb{R}^N, y^{(i)} \in \mathbb{R}^M$.
		\item \textbf{Architettura della rete}: $L$ numero di layer, $n_1, n_2, ... n_L$ numero di neuroni.
	\end{enumerate}

	\begin{algorithm}
		\caption{Backpropagation con discesa del gradiente}
		\begin{algorithmic}[1]
			\State \textbf{Inizializzazione casuale} dei parametri $\theta_0 = \{ W^{(\ell)}_0, b^{(\ell)}_0 \}$
			\For{$i = 1,2,\dotsc, N_{\text{epoche}}$}
			\For{ogni $x^{(k)} \in D_{\text{train}}$}
			\State \textbf{Input Activation:}
			\State $a^{(0)}_k = x^{(k)}$
			\For{$\ell = 1, \dotsc, L+1$}
			\State $a^{(\ell)}_k = \sigma\left( (W^{(\ell)})^T a^{(\ell-1)}_k + b^{(\ell)} \right)$
			\EndFor
			\State \textbf{Calcolo dell'errore di output:}
			\State Calcolare $\delta^{(L+1)}_k$
			\State \textbf{Backward Pass:}
			\For{$\ell = L, L-1, \dotsc, 1$}
			\State Calcolare $\delta^{(\ell)}_k$
			\EndFor
			\EndFor
			\State \textbf{Discesa del gradiente:}
			\For{$\ell = 1, \dotsc, L+1$}
			\State $W^{(\ell)}_i = W^{(\ell)}_{i-1} - \eta \frac{1}{n} \sum_{k=1}^n a^{(\ell-1)}_k \cdot \delta^{(\ell)}_k$
			\State $b^{(\ell)}_i = b^{(\ell)}_{i-1} - \eta \frac{1}{n} \sum_{k=1}^n \delta^{(\ell)}_k$
			\EndFor
			\EndFor
		\end{algorithmic}
	\end{algorithm}

	\subsection{Teorema di Approssimazione Universale}

	Sia $ \sigma : \mathbb{R} \rightarrow \mathbb{R},\  \sigma \in \mathcal{C}^1(\mathbb{R})$, e sia $f : K \subseteq \mathbb{R}^N \rightarrow \mathbb{R}^M$, dove $K$ è chiuso e limitato (ossia \textit{compatto}), $f \in \mathcal{C}^0(K)$ (ossia $f$ ha min e max in $K$), fissato $\epsilon > 0$, allora esistono:

	\begin{itemize}
		\item $n_1 \in \mathbb{N}$, neuroni del I strato;
		\item $W^{(1)} \in \mathbb{R}^{N \times n_1}, \ W^{(2)} \in \mathbb{R}^{n_1 \times M} $;
		\item $b^{(1)} \in \mathbb{R}^{n_1}$. ($W$ e $b$ parametri $\theta$)
	\end{itemize}

	tali che la funzione

	\[
	\tilde{F} : \mathbb{R}^N \rightarrow \mathbb{R}^M
	\]
	\[
	\tilde{F} (x) = W^{(2) T} \cdot \sigma ( W^{(1) T} \cdot x + b^{(1)})
	\]

	soddisfa:

	\[
	\max_{x \in K} \| \tilde{F} (x) - f(x) \| < \epsilon
	\]

	\section{Visione Artificiale}

	Conosciuta anche come \textbf{Computer Vision} (CV), ha l'obiettivo di creare un \textbf{modello} del mondo reale a partire da \textbf{immagini bidimensionali}. Posso avere:

	\begin{itemize}
		\item Più di un'immagine (es. ricostruzione 3D);
		\item Immagini \textit{non} nello spettro visibile;
		\item Immagini \textit{statiche} o in \textit{movimento} (es. video).
	\end{itemize}

	\definizione Si dice \textbf{Immagine} una funzione $f : \mathbb{R}^2 \rightarrow \mathcal{C} \subseteq \mathbb{R}^3$, dove $\mathcal{C}$ è detto \textbf{spazio colorimetrico}.

	\subsection{Immagini digitalizzate}

	Data $f : \mathbb{R}^2 \rightarrow \mathcal{C}$ si ha che:

	\begin{itemize}
		\item $\mathbb{R}^2$ si dice \textbf{campionamento}. Scompone l'immagine in \textit{pixel} creando una griglia $H \times W$ (risoluzione grafica).
		\item $\mathcal{C}$ si dice \textbf{quantizzazione} . Dipende da $\mathcal{C}$:
		\begin{enumerate}
			\item \textbf{RGB} $\subseteq \mathbb{R}^3$ Red, Green, Blue;
			\item \textbf{HSV} $ \subseteq \mathbb{R}^3$ Hue (Tonalità), Saturation, Value;
			\item \textbf{CMYB} $ \subseteq \mathbb{R}^4$ Cyan, Magenta, Yellow, Black;
 		\end{enumerate}
 		Ha 2 parametri:
 		\begin{itemize}
 			\item $N_B$, numero di bit;
 			\item $N_C$, numero di colori da rappresentare.
 		\end{itemize}
 		$ 2^{N_B} \geq N_C \iff N_B \geq \log_2 N_C, \ N_B = \left\lceil \log_2 N_C \right\rceil$
	\end{itemize}

	\esempio Codifica \textbf{Truecolor}, RGB

	24 bit $ \implies $ 8 bit R, 8 bit G, 8 bit B $\implies 2^{24} \sim 16$ milioni di colori. (Vedi immagine appunti Iotti 03\_visione artificiale). \\

	\definizione Si dice \textbf{Tensore} un'applicazione multilineare a valori in $\mathbb{R}$.

	\[
	T : V \times V \times ... \times V \times V^* \times V^* \times ... \times V^* \rightarrow \mathbb{R}\ \ (V^N \times V^{*M} \rightarrow \mathbb{R})
	\]

	dove $V$ è uno \textit{spazio vettoriale} e $V^*$ il suo \textit{duale}, ovvero $V^* = \{ \alpha : V \rightarrow \mathbb{R} \text{ lineari }\}$. \\

	\esempio Una matrice $M \in \mathbb{R}^{a \times b}$ in realtà è definita dalla seguente applicazione lineare:

	\[
	M : V \times V \rightarrow \mathbb{R}
	\]
	\[
	(i,j) \mapsto m_{ij}
	\]

	\[
	M = \begin{bmatrix}
		m_{11} \ m_{12} \ ... \ m_{1b} \\
		\vdots \\
		m_{a1} \ m_{a2} \ ...  m_{ab}
	\end{bmatrix}, \ V^* \times V^* = \{ f : V \times V \rightarrow \text{ lineari } \}
	\]

	Da cui si può ottenere:

	\[
	T : V \times ( V^* \times V^* ) \rightarrow \mathbb{R}
	\]
	\[
	(i, M) \mapsto T_{jk}^i
	\]

	\definizione Si dice \textbf{Immagine Digitalizzata} in codifica \textit{Truecolor} un \textit{tensore}
	\[
	I : \mathbb{R}^3 \times ( \mathbb{R}^{H*} \times \mathbb{R}^{W*}) \rightarrow \mathbb{R}
	\]
	rappresentabile da tre matrici $R,G,B \in \mathbb{R}^{H \times W}$ e t.c. $0  \leq I_{jk}' \leq 2^8 - 1$. \\

	\esempio \textbf{Immagini su scala di grigi}

	Immagine Luminanza

	\[
	L := 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B
	\]

	Immagini Media

	\[
	M := (R + G + B)/3
	\]

	\subsection{Notazione/Nomenclatura}

	Visione Artificiale è composta da:
	\begin{enumerate}
		\item Basso Livello
		\begin{itemize}
			\item \textbf{Acquisizione} (Acquisition) fotocamere, illuminazione, calibrazione $\implies$ \textit{Immagine Digitalizzata}.
			\item fase di \textit{Pre-processing} e \textit{Freature Extraction} (coordinate di estremi di segmenti/curve ) per arrivare a \textbf{Descrizione Simbolica} ("etichette" non semantiche).
			\item fase di \textbf{Segmentazione}, partizionamento (non semantico) dell'immagine.
		\end{itemize}
		\item Alto Livello
		\begin{itemize}
			\item \textbf{Riconoscimento} (Recognition), caratteristiche generali $\implies$ conoscenza (es oggetto di forma circolare).
			\item \textbf{Identificazione} (Identification), istanziamo questa conoscenza (es. nell'immagine c'è una pallina da tennis).
			\item \textbf{Detection}, Bounding Box o Mask (es la pallina si sta muovendo)
		\end{itemize}
	\end{enumerate}

	Infine, il sistema di visione (basso + alto) deve prendere una \textbf{decisione}.

	\subsection{Visione di Basso Livello}

	Operazioni su Immagini Digitali:
	\begin{itemize}
		\item seriali
		\item in parallelo
	\end{itemize}

	\noindent Gli \textbf{operatori} possono essere:
	\begin{itemize}
		\item \textbf{Puntuali}, su un singolo pixel (opera in parallelo)
		\item \textbf{Locali}, su pixel + intorno (in serie, l'ordine cambia)
		\item \textbf{Globali}, su tutti i pixel (es. RGB $\implies$ scala di grigi)
	\end{itemize}

	\definizione Si dice \textbf{Istogramma dei Livelli di Grigio} una funzione

	\[
	h : \{ 0,1,2, ..., 2^n - 1\} \rightarrow \mathbb{N}
	\]
	\[
	h(l) := | \{ L_{ij} = l : i = 1,2,...,H, \ j= 1,2,...,W  \} |
	\]
	\[
	t(l) := | \{ h(l) \geq T \}|
	\] \\

	\osservazione $ \sum_{l = 0}^{2^n - 1} t(l) = $ area dell'oggetto (in pixel).

	\[
	\sum_{l = 0}^{2^n - 1} h(l) = H \cdot W, \ \tilde{h} \text{ istogramma normalizzato } \sum_{l = 0}^{2^n - 1} \tilde{h}(l) = 1
	\]

	\subsubsection{Operatori Puntuali (Trasformazioni)}

	$\{ h_0, h_1, h_2, ..., h_{2^n - 1}\} \implies \{ \hat{h}_0, \hat{h}_1, \hat{h}_2, ..., \hat{h}_{2^n - 1} \}$ \\

	\definizione \textbf{Inversione} dei livello di grigio

	\begin{itemize}
		\item nel \textbf{continuo} $ f : \mathbb{R} \rightarrow \mathcal{C}$. \\
		Definizione di una funzione $i(t) = N_l - t$:
		\[
		i(f(x)) = N_l - f(x)
		\]
		\item nel \textbf{discreto} $ L \in \mathbb{R}^{H \times W}$
		\[
		I \in \mathbb{R}^{H \times W}, \ I_{ij} = N_l - L_{ij} \text{ con } i = 1,..,H, \ j = 1,...,W
		\]
	\end{itemize}

	\definizione \textbf{Compressione Logaritmica}, \textbf{espande} i livelli \textit{bassi} e \textbf{comprime} i livelli \textit{alti}.

	\begin{itemize}
		\item nel \textbf{continuo}:
		\[
		l(t) = \frac{1}{1 + N_l} \log(1 + t)
		\]
		\[
		l(f(x)) = \frac{1}{1 + N_l} \log (1 + f(x))
		\]
		\item nel \textbf{discreto}:
		\[
		Y_{ij} = \frac{1}{1 + N_l} \log (1 + L_{ij})
		\]
	\end{itemize}

	\definizione \textbf{Compressione Potenza} di parametro $\gamma > 0, \gamma \in \mathbb{R}$.

	\begin{itemize}
		\item nel \textbf{continuo}:
		\[
		p(t) = N_l^{1 - \gamma} \cdot t^\gamma
		\]
		\[
		p(f(x)) = N_l^{\ - \gamma} \cdot (f(x))^\gamma
		\]
		\item nel \textbf{discreto}:
		\[
		P_{ij} = N_l^{1 - \gamma} \cdot L_{ij}
		\]
	\end{itemize}
	Se $\gamma  \in (0,1)$ è simili alla compressione logaritmica.\\
	Se $\gamma = 1 \implies P_{ij} = L_{ij}$ .\\
	Se $\gamma > 1 $, comprime gli \textit{scuri}. \\

	\definizione \textbf{Espansione del Contrasto}, rispetto a un valore di soglia $T$.

	\begin{itemize}
		\item nel \textbf{continuo}:

		\[
		y(t) = \begin{cases}
			0 & \text{ se } t < T \\
			N_l \cdot \frac{t - T}{N_l - T} & \text{ se } t \geq T
		\end{cases}
		\]

		\[
		y(f(x)) = \begin{cases}
			0 & \text{ se } f(x) < T \\
			N_l \cdot \frac{f(x) - T}{N_l - T} & \text{ se } f(x) \geq T
		\end{cases}
		\]
		\item nel \textbf{discreto}:

		\[
		Y_{ij} = \begin{cases}
			0 & \text{ se } L_{ij} < T \\
			N_l \cdot \frac{L_{ij} - T}{N_l - T} & \text{ se } L_{ij} \geq T
		\end{cases}
		\]
	\end{itemize}

	L'\textit{implementazione} viene effettuata tramite lookup-tables (Lut o Colormap)

	\subsubsection{Operatori Locali}

	\begin{itemize}
		\item \textbf{Filtri di Sharpening}, operano sui \textit{contorni} (edges) per dare nitidezza.
		\item \textbf{Filtri di Smoothing}, per \textit{sfocare} l'immagine e ridurre il \textit{rumore}.
	\end{itemize}

	\begin{enumerate}
		\item Pixel + vicinato. \\
		\textbf{Vicinato}: sottomatrice di $L \in \mathbb{R}^{H \times W}$ quadrata e di dimensione $n$ dispari. Esso viene modificato da una \textbf{maschera} o \textbf{kernel} o \textbf{filtro}. Il metodo utilizzato è quello della \textbf{Differenziazione spaziale} (vedi appunti Iotti 03\_visione artificiale). \\

		\textbf{\underline{Problema}}: Cosa significa calcolare $\nabla I$ dove $I$ è una immagine digitalizzata? \\
		\textbf{\underline{Soluzione}}: Approssimare con Polinomi di Taylor \ref{subsec:taylor} di $f: \mathbb{R}^N \rightarrow \mathbb{R}$.
	\end{enumerate}

	\subsubsection{Operatori Locali Differenziabili}

	\definizione Il \textbf{filtro di Sobel} è un filtro (di sharpening) del \textit{I ordine} di dim $n \in \mathbb{N}$.

	\[
	x_0 =(x,y), \ h,k \in \mathbb{Z} \text{ e } x = (x + h, y + k), \ x_0 \text{ è in un intorno di } \mathcal{B}(x_0,r).
	\]

	Polinomio di Taylor su $f : \mathbb{R}^2 \rightarrow \mathcal{C}$:

	\begin{align*}
		f(x + h, y + k) \cong\
		& f(x, y)
		+ \frac{\partial f}{\partial x}(x, y) \cdot (x + h - x)^1 \cdot (y + k - y)^0 \\
		& + \frac{\partial f}{\partial y}(x, y) \cdot (x + h - x)^0 \cdot (y + k - y)^1 \\
		=\
		& f(x, y)
		+ \frac{\partial f}{\partial x}(x, y) \cdot h
		+ \frac{\partial f}{\partial y}(x, y) \cdot k
	\end{align*}

	Se $k = 0$:

	\[
	f(x+h,y) \cong f(x,y) + \frac{\partial f}{\partial x}(x,y) \cdot h, \text{ con } \frac{\partial f}{\partial x} (x,y) \cong \frac{f(x + h,y) - f(x,y)}{h}
	\]

	allora se $h = 1$ ho:

	\[
	\frac{\partial f}{\partial x} (x,y) \cong \frac{f(x + 1,y) - f(x,y)}{1}
	\]

	Se $h = 0$ e $k = 1$:

	\[
	\frac{\partial f}{\partial y}(x,y) \cong \frac{f(x, y + 1) - f(x,y)}{1}
	\]

	Per $(x - 1, y -1 )$ si ha $k = h = -1$:

	\begin{equation}
		f(x - 1, y - 1) \cong f(x,y) - \frac{\partial f}{\partial x}(x,y) - \frac{\partial f}{\partial y}(x,y),
	\label{eq:1}
	\end{equation}


	mentre per $(x + 1, y + 1)$ si ha $k = h = 1$:

	\begin{equation}
		f(x + 1, y + 1) \cong f(x,y) + \frac{\partial f}{\partial x}(x,y) + \frac{\partial f}{\partial y}(x,y)
	\label{eq:2}
	\end{equation}

	Considero le seguenti:

	\[
	(\ref{eq:1}) - (\ref{eq:2}) : f(x-1,y-1) - f(x + 1, y+1) \cong -2(\frac{\partial f}{\partial x}(x,y) + \frac{\partial f}{\partial y}(x,y))
	\]
	\[
	(\ref{eq:2}) - (\ref{eq:1}) : f(x+1,y+1) - f(x - 1, y-1) \cong \ 2(\frac{\partial f}{\partial x}(x,y) + \frac{\partial f}{\partial y}(x,y))
	\]

	Ho anche che:

	\[
	\frac{\partial f}{\partial x}(x,y) + \frac{\partial f}{\partial y}(x,y) \cong \frac{f(x+1,y+1) - f(x-1,y-1)}{2}
	\]

	Se invece si ha $h = 1, k = -1$:

	\begin{equation}
		f(x + 1, y -1) \cong f(x,y) + \frac{\partial f}{\partial x}(x,y) - \frac{\partial f}{\partial y}(x,y)
	\label{eq:3}
	\end{equation}

	mentre per $h = -1, k = 1$:

	\begin{equation}
		f(x-1,y+1) \cong f(x,y) - \frac{\partial f}{\partial x}(x,y) + \frac{\partial f}{\partial y}(x,y)
	\label{eq:4}
	\end{equation}

	%%Riprendi da HW
\end{document}
